\section{本論}
\subsection{課題1}
\begin{itemize}
  \item 運用前にチューニングを行って十分な精度が得られていた識別器で何が起こっていると
  言えるか
  \begin{itemize}
    \item[→] 運用前にチューニングを行って十分な精度が得られていた識別器が、本番環境で
    十分な精度を得られなかったのは、過学習が起きていたからだと考えられる。
    過学習とは、学習データに存在する外れ値(同じクラスの他の値から大きく離れた値)なども含めて、識別器が過剰に適合してしまい、データの変化に
    識別器が対応できず、精度が落ちてしまうことである。
    例えば、識別境界が線形ベクトルの場合、データを2分して判別することしか出来ないため、識別機の自由度は低い。
    そのため、データに外れ値が存在していたとしても、外れ値を識別するためには、識別境界を外れ値に合わせる必要があり、その場合には他の多くの値が識別できなくなるため、
    そのような識別境界は選択されない。その結果として、外れ値の識別境界への影響は少ないといえる。
    しかし、識別境界が非線形ベクトルの場合、識別境界のベクトルの次元数を上げることで、どのような曲線でも描くことができるようになり、識別器の自由度は高くなる。
    そのため、他の多くのデータを識別したまま、学習データの外れ値なども識別することができる(学習時の精度は高い)。
    しかし、学習データの数は有限であるため、外れ値の周りに存在する識別空間の全てにデータが存在することはない。
    そのため、空白である周りの識別空間は、外れ値の定義より、誤識別されている可能性が高く、その結果として
    本番環境で、学習時には空白だった識別空間のデータが与えられた際に精度が落ちてしまう。
  \end{itemize}
  \item それを回避するにはどのような方策が考えられるか
  \begin{itemize}
    \item 単純な識別機を使う。‥線形サポートベクトルマシンなどの単純モデルは、AdaBoostや非線形サポートベクトルマシンなどに比べて、識別器の自由度が低いため、過学習を抑えることができる。
    \item 学習データを大量に用意する。‥識別機の自由度が高いほど大量のデータが必要となり、データが多いほど誤識別の可能性は低くなる。
    \item Dropoutや正則化などを組み込む。‥学習に使用するデータを工夫して使うことで過学習を抑える。
  \end{itemize}
\end{itemize}

\subsection{課題2}
\begin{itemize}
  \item 「もはやSVMを使用する理由はない」という理由
  \begin{itemize}
    \item[→] SVMを使う必要がない理由として、SVMは、データ量に対するパフォーマンスが悪く、計算量が多くなること、解釈性に難があることなどが考えられ、
    また、ディープラーニングなどのパフォーマンスが良い手法が発展していることなども考えられる。
    カーネルSVMでは、グラム行列と呼ばれるデータ数*データ数の行列を計算する必要があるため、データ数が膨大になるほど、計算が爆発的に増えて、多くのメモリが必要となるなど、
    ビッグデータを扱う現代では、致命的な弱点を持っている。
    その上で、ディープラーニングでは、同じような非線形問題を解くことができる上に、計算負荷もデータ数に
    応じて線形に近い増加、並列処理とも相性がいいなどの利点を持っている。
  \end{itemize}
  \item それでもこの講義においてSVMを取り扱った理由
  \item \begin{itemize}
    \item[→] SVMは、今では使われることが少なくなったものの、今でもSVMが良い選択であるような問題も存在する。
    そして、様々な問題を解決する際には、それぞれ最適となる手法が存在する。その際に、多種多様な手法を知っていることは
    、それだけ解決するための選択肢が多いということであり、また、どの問題に、どの手法が適しているかを理解することができることなどが考えられる。
  \end{itemize}
\end{itemize}

\subsection{課題3}