\section{考察}
\subsection{課題1}
\begin{itemize}
  \item 表\ref{table:1}と表\ref{table:6}を見ると、最初の2回分の処理時間が3回目以降の処理時間
  と比べて異常に長い。しかし、これらの処理は全て同じであり、本来は同じ処理時間が計測できる
  はずである。それに比べて、3回目以降は処理時間が安定しており、20回目以降も安定していると思われる。
  その中で、「Thread.sleep();」を使ったテストでは見られなかった「最初の2回だけ処理時間が長い」
  という現象は、ハードウェア的な問題であると考えられる
  。というのも、メディアンフィルタではソートなどを行うため、
  メソッドや配列などがあるメモリなどへのアクセスが頻繁に起こり、
  そういったアクセス時間が今回の計測結果の最初の2回分に影響したのではないかと考察した。
  また、3回目以降の計測時間が安定しているのは、最初の2回分の計測によるメモリへのアクセス過程で、
  メモリへのアクセスを高速化するパスのようなものが作成されていると考え、
  そのおかげであると考察した。
  \item 画像処理10回分、または画像処理20回分、繰り返してその回数で割った
  表\ref{table:2}と表\ref{table:3}の計測結果が1回分のデータと比べて
  、処理時間が短く安定しているように見えるのは、平均を取っているおかげであると考えられる。
  つまり、表\ref{table:2}と表\ref{table:3}でも、表\ref{table:1}と同様に、最初の2回分の
  処理時間が  異常に長くなっているが、その後の安定した「3回目以降の結果」で平均を取っているため、
  結果が安定しているように見えると思われる。実際に、表\ref{table:2}と表\ref{table:3}でも、
  1回目のデータは、他のデータに比べて「1,2ms」大きくなっている。
  しかし、こういった誤差は繰り返し回数を増やせば増やすほど、
  安定したデータが増えるために、減っていくと考察できる。
\end{itemize}

\subsection{課題2}
\begin{itemize}
  \item 表\ref{table:4}と表\ref{table:5}では、最終的な出力結果は同じで、違いはアルゴリズムだ
  けであるはずだが、処理時間は最初の2回だけなら、2倍弱も変わってしまっている。
  つまり、使うアルゴリズムによって処理時間は大きく変わるということになる。
  表\ref{table:4}で使ったバブルソートは、全てのデータを1つずつ比較してソートするアルゴリズムで
  あるため、メモリへのアクセス数は多いと考えられる。
  一方のクイックソートは、データを分けてソートするため、バブルソート
  よりはメモリへのアクセス数は少ないと考えられる。
  そのため、バブルソートを使ったプログラムよりもクイックソートを使ったプログラム
  の方が、処理時間が短くなったと考えられる。
\end{itemize}